	.file	"forward.cpp"
	.text
	.p2align 4
	.globl	_Z7forwardiiiiiiiiiiiiPiS_S_S_S_S_S_S_S_S_S_S_
	.type	_Z7forwardiiiiiiiiiiiiPiS_S_S_S_S_S_S_S_S_S_S_, @function
_Z7forwardiiiiiiiiiiiiPiS_S_S_S_S_S_S_S_S_S_S_:
.LFB0:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	movl	%esi, %r11d
	movl	%edx, %r15d
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	movl	%r9d, %r13d
	movl	%r11d, %r9d
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	movl	%r8d, %r12d
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	movl	%ecx, %ebp
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	movl	%edi, %ebx
	movl	%ebx, %eax
	movl	%ebx, %r10d
	movl	%ebx, %r14d
	imull	%r11d, %eax
	movl	%ebx, %r11d
	imull	%r15d, %r11d
	subq	$24, %rsp
	.cfi_def_cfa_offset 80
	movl	96(%rsp), %edi
	imull	%r12d, %r10d
	movl	104(%rsp), %esi
	movl	%ebx, 20(%rsp)
	movl	88(%rsp), %r8d
	imull	%ebp, %r14d
	movl	112(%rsp), %ecx
	movl	%r9d, %ebx
	movl	%r11d, -112(%rsp)
	movl	%r9d, %r11d
	movl	120(%rsp), %edx
	movl	%ebp, %r9d
	imull	%r13d, %r11d
	movl	%r12d, -120(%rsp)
	movl	%r10d, -88(%rsp)
	imull	%r13d, %r9d
	movl	%r14d, -104(%rsp)
	movl	%r15d, %r14d
	movl	%r11d, -84(%rsp)
	movl	%r12d, %r11d
	imull	%r13d, %r14d
	movl	%r8d, %r12d
	imull	%edi, %r12d
	movl	%ebx, -20(%rsp)
	movl	%r13d, -116(%rsp)
	imull	%r13d, %r11d
	movl	%r14d, -100(%rsp)
	movl	%r12d, %r10d
	movl	%r12d, -64(%rsp)
	movl	%ebp, %r12d
	imull	%esi, %r10d
	movl	%r9d, -80(%rsp)
	movl	80(%rsp), %r9d
	movl	%r11d, -76(%rsp)
	imull	%r8d, %r9d
	imull	%ecx, %r10d
	movl	%r9d, -96(%rsp)
	imull	%edi, %r9d
	movl	%r10d, %r14d
	movl	%ebx, %r10d
	imull	%r15d, %r10d
	imull	%edx, %r14d
	movl	%r9d, %r13d
	movl	%r9d, %r11d
	imull	%esi, %r13d
	imull	%r10d, %r12d
	movl	%r10d, %ebx
	movl	%r14d, -60(%rsp)
	movl	-116(%rsp), %r14d
	movl	%r13d, %r9d
	imull	%ecx, %r13d
	movl	%r12d, %r10d
	movl	-120(%rsp), %r12d
	imull	%r12d, %r10d
	movl	%r13d, -68(%rsp)
	imull	%r10d, %r14d
	movl	%r14d, -56(%rsp)
	imull	80(%rsp), %r14d
	movl	%r15d, -16(%rsp)
	movl	%ebp, -108(%rsp)
	movl	%r14d, %r10d
	movl	-20(%rsp), %r14d
	imull	%r8d, %r10d
	imull	%edi, %r10d
	imull	%esi, %r10d
	movl	%r10d, %r13d
	movl	%r15d, %r10d
	imull	%eax, %r10d
	imull	%ecx, %r13d
	movl	%r10d, -24(%rsp)
	imull	%ebp, %r10d
	movl	%r13d, -52(%rsp)
	movl	%r10d, %ebp
	movl	%r10d, -12(%rsp)
	imull	%r12d, %ebp
	movl	-116(%rsp), %r12d
	imull	%ebp, %r12d
	movl	%ebp, -72(%rsp)
	movl	80(%rsp), %ebp
	imull	%r12d, %ebp
	movl	%r12d, -8(%rsp)
	movl	%ebp, %r12d
	movl	%ebp, -4(%rsp)
	movl	80(%rsp), %ebp
	imull	%r8d, %r12d
	movl	%r12d, %r15d
	movl	%r12d, (%rsp)
	movq	128(%rsp), %r12
	imull	%edi, %r15d
	addl	%eax, %ebp
	addl	-112(%rsp), %ebp
	addl	-104(%rsp), %ebp
	addl	-88(%rsp), %ebp
	addl	-84(%rsp), %ebp
	addl	-100(%rsp), %ebp
	addl	-80(%rsp), %ebp
	movl	%r15d, %r10d
	imull	%esi, %r15d
	addl	-76(%rsp), %ebp
	addl	-68(%rsp), %ebp
	addl	-60(%rsp), %ebp
	addl	%r13d, %ebp
	movl	%r15d, %r13d
	imull	%ecx, %r13d
	addl	%r13d, %ebp
	movl	-120(%rsp), %r13d
	movl	%ebp, (%r12)
	movl	-108(%rsp), %ebp
	movl	-16(%rsp), %r12d
	imull	%ebp, %r14d
	imull	%r13d, %r12d
	imull	%r13d, %ebp
	movl	%r9d, %r13d
	movl	80(%rsp), %r9d
	imull	%edx, %r13d
	imull	%edi, %r9d
	movl	%r13d, -48(%rsp)
	movl	%r9d, -92(%rsp)
	imull	%esi, %r9d
	imull	%ecx, %r9d
	movl	%r9d, %r13d
	movl	-112(%rsp), %r9d
	imull	-108(%rsp), %r9d
	imull	%edx, %r13d
	movl	%r13d, -44(%rsp)
	imull	-120(%rsp), %r9d
	movl	-116(%rsp), %r13d
	imull	%r9d, %r13d
	movl	%r13d, -40(%rsp)
	imull	80(%rsp), %r13d
	movl	%r13d, %r9d
	imull	%r8d, %r9d
	imull	%edi, %r9d
	movl	%r9d, %r13d
	leal	(%rax,%r8), %r9d
	imull	%esi, %r13d
	addl	%ebx, %r9d
	movl	%r13d, 4(%rsp)
	imull	%edx, %r13d
	addl	%r14d, %r9d
	addl	-88(%rsp), %r9d
	imull	%edx, %r15d
	addl	%r12d, %r9d
	addl	%ebp, %r9d
	imull	%ecx, %r11d
	addl	-84(%rsp), %r9d
	addl	-76(%rsp), %r9d
	addl	-48(%rsp), %r9d
	addl	-44(%rsp), %r9d
	movl	%r13d, -36(%rsp)
	addl	%r13d, %r9d
	movl	-116(%rsp), %r13d
	addl	%r9d, %r15d
	movq	136(%rsp), %r9
	imull	%edx, %r11d
	movl	%r15d, (%r9)
	movl	-108(%rsp), %r9d
	movl	-96(%rsp), %r15d
	imull	%eax, %r9d
	imull	-120(%rsp), %r9d
	imull	%esi, %r15d
	imull	%r9d, %r13d
	imull	%ecx, %r15d
	movl	%r13d, -32(%rsp)
	imull	80(%rsp), %r13d
	imull	%edx, %r15d
	movl	%r13d, %r9d
	imull	%r8d, %r9d
	imull	%edi, %r9d
	movl	%r9d, 8(%rsp)
	imull	%ecx, %r9d
	imull	%edx, %r9d
	movl	%r9d, %r13d
	movl	-112(%rsp), %r9d
	movl	%r13d, -28(%rsp)
	addl	%edi, %r9d
	addl	%ebx, %r9d
	addl	-104(%rsp), %r9d
	addl	%r14d, %r9d
	addl	%r12d, %r9d
	addl	%ebp, %r9d
	addl	-100(%rsp), %r9d
	addl	-80(%rsp), %r9d
	addl	%r11d, %r9d
	imull	%ecx, %r10d
	addl	%r15d, %r9d
	addl	%r13d, %r9d
	imull	%edx, %r10d
	addl	%r9d, %r10d
	movq	144(%rsp), %r9
	movl	%r10d, (%r9)
	movl	-24(%rsp), %r9d
	imull	-120(%rsp), %r9d
	imull	-116(%rsp), %r9d
	movl	%r9d, %r10d
	imull	80(%rsp), %r10d
	movl	%r9d, -24(%rsp)
	imull	%r8d, %r10d
	movl	%r10d, 12(%rsp)
	imull	%esi, %r10d
	movl	-80(%rsp), %r13d
	movl	%r10d, %r9d
	imull	%ecx, %r9d
	movl	%r9d, %r10d
	movl	-112(%rsp), %r9d
	imull	%edx, %r10d
	addl	%esi, %r9d
	addl	%ebx, %r9d
	addl	-104(%rsp), %r9d
	addl	%r14d, %r9d
	movl	%r10d, 16(%rsp)
	addl	%r12d, %r9d
	addl	%ebp, %r9d
	addl	-100(%rsp), %r9d
	addl	%r13d, %r9d
	addl	%r11d, %r9d
	addl	%r15d, %r9d
	leal	(%r9,%r10), %r10d
	movl	(%rsp), %r9d
	imull	%esi, %r9d
	imull	%ecx, %r9d
	imull	%edx, %r9d
	addl	%r10d, %r9d
	movq	152(%rsp), %r10
	movl	%r9d, (%r10)
	movl	-12(%rsp), %r10d
	imull	-116(%rsp), %r10d
	movl	%r10d, %r11d
	imull	80(%rsp), %r11d
	movl	%r10d, -80(%rsp)
	movl	-4(%rsp), %r10d
	movl	%r11d, %r9d
	movl	%r11d, -12(%rsp)
	movl	-84(%rsp), %r11d
	imull	%edi, %r9d
	imull	%esi, %r9d
	imull	%ecx, %r9d
	movl	%r9d, %r15d
	leal	(%rax,%rcx), %r9d
	imull	%edx, %r15d
	addl	%ebx, %r9d
	movl	-88(%rsp), %ebx
	addl	%edx, %eax
	addl	%r14d, %r9d
	imull	%edi, %r10d
	addl	-112(%rsp), %eax
	addl	-104(%rsp), %eax
	addl	%ebx, %r9d
	addl	%ebx, %eax
	movl	%r8d, %ebx
	addl	%r12d, %r9d
	movl	%r15d, -88(%rsp)
	addl	%r11d, %eax
	addl	-100(%rsp), %eax
	addl	%ebp, %r9d
	movl	-76(%rsp), %ebp
	imull	%esi, %r10d
	addl	%r13d, %eax
	addl	%r11d, %r9d
	movl	%edi, %r11d
	addl	%ebp, %r9d
	addl	-48(%rsp), %r9d
	addl	-44(%rsp), %r9d
	addl	%ebp, %eax
	addl	%r15d, %r9d
	movl	-72(%rsp), %r15d
	imull	%ecx, %r10d
	movl	-68(%rsp), %ebp
	movl	%r15d, %r14d
	imull	%r8d, %r14d
	imull	%edx, %r10d
	imull	%edi, %r14d
	addl	%r10d, %r9d
	movq	160(%rsp), %r10
	imull	%esi, %r14d
	movl	%r9d, (%r10)
	leal	(%rax,%rbp), %r9d
	movl	-8(%rsp), %eax
	addl	-60(%rsp), %r9d
	movl	80(%rsp), %ebp
	imull	%r8d, %eax
	imull	%ecx, %r14d
	imull	%edx, %r14d
	addl	%r14d, %r9d
	imull	%edi, %eax
	imull	%esi, %ebp
	imull	%edx, %ebx
	imull	%esi, %eax
	movl	%ebp, %r12d
	imull	%edx, %r11d
	imull	%ecx, %eax
	imull	%edx, %eax
	addl	%r9d, %eax
	movq	168(%rsp), %r9
	movl	%eax, (%r9)
	movl	%esi, %eax
	movl	80(%rsp), %ebp
	imull	%edx, %eax
	movq	176(%rsp), %r13
	imull	%ecx, %ebp
	movl	%eax, %r10d
	movl	%ecx, %eax
	imull	%edx, %eax
	movl	%eax, %r9d
	movl	20(%rsp), %eax
	addl	80(%rsp), %eax
	addl	-96(%rsp), %eax
	addl	-92(%rsp), %eax
	addl	%r12d, %eax
	addl	%ebp, %eax
	addl	%ebx, %eax
	addl	%r11d, %eax
	addl	%r10d, %eax
	addl	%r9d, %eax
	addl	%r15d, %eax
	addl	-56(%rsp), %eax
	addl	%eax, %r14d
	movl	80(%rsp), %eax
	imull	%r15d, %eax
	imull	%r8d, %eax
	imull	%edi, %eax
	imull	%esi, %eax
	imull	%ecx, %eax
	imull	%edx, %eax
	addl	%r14d, %eax
	movl	%r8d, %r14d
	imull	%esi, %r14d
	movl	%eax, 0(%r13)
	movl	%esi, %eax
	movl	%r14d, %r15d
	movl	%edi, %r14d
	imull	%ecx, %r14d
	imull	%ecx, %eax
	movl	%eax, %r13d
	movl	-20(%rsp), %eax
	addl	%r8d, %eax
	imull	-12(%rsp), %r8d
	addl	-96(%rsp), %eax
	addl	-64(%rsp), %eax
	addl	%r15d, %eax
	imull	%edi, %r8d
	addl	%ebp, %eax
	addl	%r14d, %eax
	addl	%r13d, %eax
	imull	%esi, %r8d
	addl	%ebx, %eax
	addl	%r9d, %eax
	addl	-80(%rsp), %eax
	addl	-40(%rsp), %eax
	addl	-88(%rsp), %eax
	imull	%ecx, %r8d
	imull	%edx, %r8d
	addl	%r8d, %eax
	movq	184(%rsp), %r8
	movl	%eax, (%r8)
	movl	-16(%rsp), %eax
	movl	-64(%rsp), %r8d
	addl	%edi, %eax
	imull	12(%rsp), %edi
	addl	-92(%rsp), %eax
	addl	%r8d, %eax
	addl	%r12d, %eax
	addl	%r15d, %eax
	addl	%r14d, %eax
	addl	%r13d, %eax
	addl	%r11d, %eax
	addl	%r10d, %eax
	addl	-24(%rsp), %eax
	addl	-32(%rsp), %eax
	addl	16(%rsp), %eax
	imull	%esi, %edi
	imull	%ecx, %edi
	imull	%edx, %edi
	addl	%edi, %eax
	movq	192(%rsp), %rdi
	movl	%eax, (%rdi)
	movl	-108(%rsp), %eax
	addl	%esi, %eax
	addl	-92(%rsp), %eax
	addl	%r8d, %eax
	addl	%r12d, %eax
	addl	%r15d, %eax
	addl	%r14d, %eax
	addl	%r13d, %eax
	addl	%r11d, %eax
	addl	%r10d, %eax
	addl	-24(%rsp), %eax
	addl	-32(%rsp), %eax
	addl	-28(%rsp), %eax
	imull	8(%rsp), %esi
	movl	-96(%rsp), %edi
	imull	%ecx, %esi
	imull	%edx, %esi
	addl	%esi, %eax
	movq	200(%rsp), %rsi
	movl	%eax, (%rsi)
	movl	-120(%rsp), %eax
	addl	%ecx, %eax
	addl	%edi, %eax
	addl	%r8d, %eax
	addl	%r15d, %eax
	addl	%ebp, %eax
	addl	%r14d, %eax
	addl	%r13d, %eax
	movl	-52(%rsp), %r13d
	addl	%ebx, %eax
	addl	%r9d, %eax
	addl	-80(%rsp), %eax
	addl	-40(%rsp), %eax
	addl	-36(%rsp), %eax
	imull	4(%rsp), %ecx
	imull	%edx, %ecx
	addl	%ecx, %eax
	movq	208(%rsp), %rcx
	movl	%eax, (%rcx)
	movl	-116(%rsp), %eax
	addl	%edx, %eax
	imull	%r13d, %edx
	addl	%edi, %eax
	addl	-92(%rsp), %eax
	addl	%r12d, %eax
	addl	%ebp, %eax
	addl	%ebx, %eax
	addl	%r11d, %eax
	addl	%r10d, %eax
	addl	%r9d, %eax
	addl	-72(%rsp), %eax
	addl	-56(%rsp), %eax
	addl	%r13d, %eax
	addl	%edx, %eax
	movq	216(%rsp), %rdx
	movl	%eax, (%rdx)
	addq	$24, %rsp
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.cfi_endproc
.LFE0:
	.size	_Z7forwardiiiiiiiiiiiiPiS_S_S_S_S_S_S_S_S_S_S_, .-_Z7forwardiiiiiiiiiiiiPiS_S_S_S_S_S_S_S_S_S_S_
	.ident	"GCC: (GNU) 11.1.0"
	.section	.note.GNU-stack,"",@progbits
